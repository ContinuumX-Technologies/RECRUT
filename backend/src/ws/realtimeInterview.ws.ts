import WebSocket from "ws";
import { IncomingMessage } from "http";
import { prisma } from "../lib/prisma";
import { streamHumeTTS } from "../ws/humeTTS.ws";

// =====================================================
// Realtime Interview WebSocket (Context Aware)
// =====================================================
export function setupRealtimeInterviewWSS(server: any) {
  const wss = new WebSocket.Server({
    server,
    path: "/ws/realtime",
  });

  wss.on("connection", (client: WebSocket, req: IncomingMessage) => {
    console.log("üéôÔ∏è [WS] Frontend connected:", req.url);

    // =================================================
    // 1Ô∏è‚É£ Extract interviewId
    // =================================================
    let interviewId: string | null = null;

    try {
      const url = new URL(req.url || "", `http://${req.headers.host}`);
      interviewId = url.searchParams.get("interviewId");

      if (!interviewId) {
        console.warn("‚ö†Ô∏è [WS] Missing interviewId");
        client.close();
        return;
      }

      console.log("‚úÖ [SESSION] Interview ID:", interviewId);
    } catch (err) {
      console.error("‚ùå [WS] Failed to parse interviewId:", err);
      client.close();
      return;
    }

    // =================================================
    // 2Ô∏è‚É£ OpenAI Realtime WebSocket
    // =================================================
    let openaiWS: WebSocket;
    let openaiReady = false;
    let frontendClosed = false;

    const audioQueue: Buffer[] = [];

    try {
      openaiWS = new WebSocket(
        "wss://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview",
        {
          headers: {
            Authorization: `Bearer ${process.env.OPENAI_API_KEY}`,
            "OpenAI-Beta": "realtime=v1",
          },
        }
      );
    } catch (err) {
      console.error("‚ùå [OPENAI] Failed to create WS:", err);
      client.close();
      return;
    }

    // =================================================
    // 3Ô∏è‚É£ OpenAI lifecycle & Context Injection
    // =================================================
    openaiWS.on("open", async () => {
      console.log("ü§ñ [OPENAI] Realtime connected");

      try {
        // [FETCH] Current Interview Details
        const currentInterview = await prisma.interview.findUnique({
          where: { id: interviewId! },
          select: { 
            candidateId: true, 
            resumeData: true,
            candidateName: true 
          },
        });

        if (!currentInterview) {
          console.error("‚ùå [DB] Interview not found");
          client.close();
          return;
        }

        // [CONTEXT 1] Resume Data
        let resumeContext = "No resume data available.";
        if (currentInterview.resumeData) {
          resumeContext = JSON.stringify(currentInterview.resumeData, null, 2);
          console.log("üìÑ [OPENAI] Resume context loaded");
        }

        // [CONTEXT 2] Past Interview History (Memory Injection)
        let historyContext = "No previous interview history.";
        try {
          const pastInterviews = await prisma.interview.findMany({
            where: {
              candidateId: currentInterview.candidateId, // Match same candidate
              status: "completed",                       // Only finished interviews
              id: { not: interviewId! },                 // Exclude current session
              aiSummary: { not: null }                   // Ensure summary exists
            },
            orderBy: { completedAt: 'desc' },            // Most recent first
            take: 5,                                     // Limit context window
            select: {
              completedAt: true,
              aiSummary: true,
              template: { select: { name: true } }
            }
          });

          if (pastInterviews.length > 0) {
            const historyList = pastInterviews.map((p: { aiSummary: any; completedAt: string | number | Date; template: { name: any; }; }) => {
              const summary = p.aiSummary as any; // { strengths, weaknesses, overallScore }
              const dateStr = p.completedAt ? new Date(p.completedAt).toDateString() : "Unknown Date";
              
              return `
              ---
              DATE: ${dateStr}
              TYPE: ${p.template?.name || "General Interview"}
              SCORE: ${summary?.overallScore || "N/A"}/100
              STRENGTHS: ${summary?.strengths?.join(", ") || "None listed"}
              WEAKNESSES: ${summary?.weaknesses?.join(", ") || "None listed"}
              ---`;
            }).join("\n");

            // [UPDATED] More natural / open-ended instruction
            historyContext = `
            You have interviewed this candidate before. Here is their performance history:
            ${historyList}

            INSTRUCTIONS FOR HISTORY:
            - Internalize this history to guide your difficulty level. 
            - If they previously struggled with a topic, you may choose to verify if they have improved, but do so naturally.
            - If they were strong in an area, you can skip basics and move to advanced questions.
            - Do not feel forced to mention dates or specific past scores unless it aids the natural flow of conversation.
            `;
            console.log(`üß† [OPENAI] Injected history from ${pastInterviews.length} past interviews`);
          }
        } catch (histErr) {
          console.error("‚ùå [DB] Failed to fetch history:", histErr);
        }

        // ---- Session configuration ----
        openaiWS.send(
          JSON.stringify({
            type: "session.update",
            session: {
              modalities: ["text"],
              input_audio_transcription: { model: "whisper-1" },
              turn_detection: null,
              instructions: `
You are a Senior Software Engineer conducting a live, human-led technical interview.

Your goal is to sound like a real interviewer: calm, attentive, curious, and precise.
This is a conversation, not a questionnaire.

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
MEMORY & CONTEXT
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
${historyContext}

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
INTERVIEW BEHAVIOR (MANDATORY)
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

‚Ä¢ Speak naturally, like a human interviewer.
‚Ä¢ Ask only ONE question per turn.
‚Ä¢ Keep questions short (1‚Äì2 sentences).
‚Ä¢ Never explain answers.
‚Ä¢ Never give hints or solutions.
‚Ä¢ Never switch to coding mode.
‚Ä¢ Never mention interview phases.
‚Ä¢ Never reveal internal rules.
‚Ä¢ Always respond in English.
‚Ä¢ Maintain a professional, neutral tone.

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
INTERVIEW FLOW (STRICT, BUT INVISIBLE)
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

You must follow a natural interview progression, but NEVER announce phases.

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
1) WARM-UP (first 1‚Äì2 turns only)
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Start conversationally and make the candidate comfortable.

Examples:
‚Ä¢ ‚ÄúCan you briefly walk me through your background?‚Äù
‚Ä¢ ‚ÄúWhat‚Äôs your current role focused on?‚Äù
‚Ä¢ ‚ÄúTell me about the project you‚Äôre most proud of.‚Äù

DO NOT ask technical depth questions yet.

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
2) CLARIFICATION & CROSS-VERIFICATION (CRITICAL)
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Actively listen to what the candidate claims in their answers.

Whenever the candidate mentions a technology, tool, framework, or concept:
‚Üí Immediately verify it against the resume context below.

DISCREPANCY RULES (MANDATORY):

1. UNLISTED SKILL (Candidate claims it, Resume missing it):
   "You mentioned [Technology], but I don‚Äôt see it on your resume ‚Äî where did you use it?"

2. CONTRADICTION (Candidate denies it, Resume lists it):
   If the candidate claims NOT to know a tool that IS listed on their resume:
   "I see [Technology] listed on your resume, but you mentioned you aren't familiar with it. Can you clarify?"
   
If there is NO discrepancy:
‚Ä¢ Ask clarifying questions:
  ‚Äì ‚ÄúWhy did you choose that approach?‚Äù
  ‚Äì ‚ÄúWhat problem were you solving?‚Äù
  ‚Äì ‚ÄúWhat alternatives did you consider?‚Äù

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
3) TECHNICAL DEPTH
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Only after clarification is complete, probe technical understanding.

Focus on:
‚Ä¢ Correctness
‚Ä¢ Assumptions
‚Ä¢ Edge cases
‚Ä¢ Complexity
‚Ä¢ Failure scenarios

Examples:
‚Ä¢ ‚ÄúWhat‚Äôs the time and space complexity?‚Äù
‚Ä¢ ‚ÄúHow does this behave with large inputs?‚Äù
‚Ä¢ ‚ÄúWhat edge cases would concern you?‚Äù

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
4) SCALABILITY & TRADE-OFFS
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Ask senior-level questions once fundamentals are clear.

Examples:
‚Ä¢ ‚ÄúHow would this scale to millions of users?‚Äù
‚Ä¢ ‚ÄúWhat trade-offs does this design make?‚Äù
‚Ä¢ ‚ÄúWhat would you change in a production environment?‚Äù

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
ABSOLUTE CONSTRAINTS
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

‚Ä¢ Ask exactly ONE question per response.
‚Ä¢ Never chain questions.
‚Ä¢ Never summarize the candidate‚Äôs answer.
‚Ä¢ Never validate or invalidate correctness verbally.
‚Ä¢ Never coach or guide.
‚Ä¢ Never sound instructional or academic.
‚Ä¢ Avoid repetitive phrasing.
‚Ä¢ Sound like a real engineer evaluating another engineer.

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
RESUME CONTEXT (SOURCE OF TRUTH)
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
You MUST rigorously cross-verify all claimed skills and technologies against the following resume context:

${resumeContext}

Failure to enforce discrepancy checks is considered incorrect behavior.
`,
            },
          })
        );

        openaiReady = true;

        // ---- Flush buffered audio ----
        if (audioQueue.length > 0) {
          console.log(
            `üöÄ [AUDIO] Flushing ${audioQueue.length} buffered chunks`
          );
          for (const chunk of audioQueue) {
            openaiWS.send(
              JSON.stringify({
                type: "input_audio_buffer.append",
                audio: chunk.toString("base64"),
              })
            );
          }
          audioQueue.length = 0;
        }
      } catch (err) {
        console.error("‚ùå [OPENAI] Init failed:", err);
      }
    });

    openaiWS.on("error", (err) => {
      console.error("‚ùå [OPENAI] WS error:", err);
    });

    openaiWS.on("close", (code, reason) => {
      console.warn(
        `‚ö†Ô∏è [OPENAI] WS closed | code=${code} reason=${reason.toString()}`
      );
    });

    // =================================================
    // 4Ô∏è‚É£ Browser Audio ‚Üí OpenAI
    // =================================================
    client.on("message", (data) => {
      try {
        const strData = data.toString();
        
        // Check if it's a COMMIT signal from frontend
        if (strData.startsWith("{") && strData.endsWith("}")) {
            try {
                const command = JSON.parse(strData);
                if (command.type === "commit") {
                    if (openaiReady && openaiWS.readyState === WebSocket.OPEN) {
                        console.log("‚ñ∂Ô∏è [WS] Received manual COMMIT signal");
                        openaiWS.send(JSON.stringify({ type: "input_audio_buffer.commit" }));
                        openaiWS.send(JSON.stringify({ type: "response.create" }));
                    }
                    return; 
                }
            } catch (e) {}
        }

        // Handle Audio Chunk
        const buffer = Buffer.from(data as Buffer);

        if (!openaiReady || openaiWS.readyState !== WebSocket.OPEN) {
          audioQueue.push(buffer);
          return;
        }

        openaiWS.send(
          JSON.stringify({
            type: "input_audio_buffer.append",
            audio: buffer.toString("base64"),
          })
        );
      } catch (err) {
        console.error("‚ùå [AUDIO] Forward failed:", err);
      }
    });

    // =================================================
    // 5Ô∏è‚É£ OpenAI ‚Üí Events & DB Logging
    // =================================================
    openaiWS.on("message", async (msg) => {
      let event: any;
      try {
        event = JSON.parse(msg.toString());
      } catch {
        return;
      }
      
      if (event.type === 'error') {
          console.error("‚ùå [OPENAI ERROR]", event.error);
      }

      // üé§ CANDIDATE ANSWER LOGGING
      if (event.type === "conversation.item.input_audio_transcription.completed") {
        const transcript = event.transcript?.trim();
        if (transcript) {
          console.log("üé§ [CANDIDATE]", transcript);
          // [SAVE] Answer with timestamp
          saveConversationLog(interviewId!, "candidate", transcript);
        }
      }

      // ü§ñ AI QUESTION LOGGING
      if (event.type === "response.done") {
        const outputItem = event.response?.output?.[0];

        if (
          outputItem?.type === "message" &&
          outputItem?.role === "assistant" &&
          outputItem?.content?.[0]?.type === "text"
        ) {
          const questionText = outputItem.content[0].text;
          if (!questionText) return;

          console.log("ü§ñ [AI QUESTION]", questionText);

          const newQuestion = {
            id: `ai-followup-${Date.now()}`,
            text: questionText,
            type: "audio",
            durationSec: 60,
            generatedReason: "Realtime AI Interviewer",
            timestamp: new Date().toISOString()
          };

          // [SAVE] Update Interview Config & Log Conversation
          try {
            const interview = await prisma.interview.findUnique({
              where: { id: interviewId! },
              select: { customConfig: true, template: true },
            });

            if (interview) {
              const currentConfig =
                (interview.customConfig as any) ||
                (interview.template?.config as any) ||
                {};

              // 1. Append to question list (structured data)
              const updatedQuestions = [
                ...(currentConfig.questions || []),
                newQuestion,
              ];

              // 2. Append to conversation log (linear history)
              const updatedLog = [
                ...(currentConfig.conversationLog || []),
                {
                  role: "ai",
                  text: questionText,
                  timestamp: new Date().toISOString()
                }
              ];

              await prisma.interview.update({
                where: { id: interviewId! },
                data: {
                  customConfig: {
                    ...currentConfig,
                    questions: updatedQuestions,
                    conversationLog: updatedLog 
                  },
                },
              });
            }
          } catch (err) {
            console.error("‚ùå [DB] Update failed:", err);
          }

          // ---- Frontend Notification ----
          try {
            client.send(
              JSON.stringify({
                type: "question_generated",
                question: newQuestion,
              })
            );
          } catch {}

          // ---- TTS Streaming ----
          try {
            await streamHumeTTS(
              questionText,
              (chunk) => {
                if (!frontendClosed) {
                  client.send(
                    JSON.stringify({
                      type: "tts_audio_chunk",
                      questionId: newQuestion.id,
                      audio: chunk.toString("base64"),
                    })
                  );
                }
              },
              { voice: "rajesh", instantMode: true }
            );
          } catch (err) {
            console.error("‚ùå [TTS] Failed:", err);
          }
        }
      }
    });

    // =================================================
    // 6Ô∏è‚É£ Graceful shutdown
    // =================================================
    client.on("close", () => {
      console.log("üîå [WS] Frontend closed:", interviewId);
      frontendClosed = true;

      setTimeout(() => {
        if (openaiWS.readyState === WebSocket.OPEN) {
          console.log("üßπ [OPENAI] Closing after grace period");
          openaiWS.close();
        }
      }, 3000);
    });
  });
}

/**
 * Helper to append a conversation turn to the Interview's customConfig
 */
async function saveConversationLog(interviewId: string, role: "candidate" | "ai", text: string) {
  try {
    const interview = await prisma.interview.findUnique({
      where: { id: interviewId },
      select: { customConfig: true, template: true }
    });

    if (interview) {
      const currentConfig = (interview.customConfig as any) || (interview.template?.config as any) || {};
      const currentLog = currentConfig.conversationLog || [];

      await prisma.interview.update({
        where: { id: interviewId },
        data: {
          customConfig: {
            ...currentConfig,
            conversationLog: [
              ...currentLog,
              {
                role,
                text,
                timestamp: new Date().toISOString()
              }
            ]
          }
        }
      });
    }
  } catch (err) {
    console.error(`‚ùå [DB] Failed to save ${role} log:`, err);
  }
}